# 위효연 readme.md


멘토링세션 

- **김강민 멘토 인공지능 대학원 석사AI 법률 스타트업 AI 엔지니어한국 부트스트렙 과정중에서 RAG 관련 과정중 가장 업데이트된 과정이라서 판단됨.**
- **HugginsFace LLM 모델과, Prompt를 바꾸는 어프로치를 적용 (과학상식 -> 생물, 화학, 물리 등 더 자세히 바꿔 봄) 실험을 할 때, LLM 모델만 바꾸는 것은 효과가 없을 것임. 아키텍쳐를 바꾸거나, 아키텍쳐 상의 컴포넌트를 바꾸는 것이 필요함.이유를 찾을 때, 로그를 남겨야(왜 해야 하는지 당위성을 찾을 것)프롬프트를 바꾸는 것은 효과가 있음. 프롬프트 변경에 대한 이유, 히스토리를 남기는 것이 좋음.딥러닝 초보자가 할 수 있는 성능 개선 방법은 없음. Data-Centric 기반으로 접근하는 것이 좋음.무료로 사용가능한 API는 HuggingsFace에서 모델을 받아서 Self-hosted**
- **테스트 세트 먼저 만들어야 함. 실제로 도움이 되는 테스트 세트를 만들어야 함. 손으로 만들 수도 있지만, ChatGPT로 자동화하는 것이 좋음.**
- **프롬프트 엔지니어링RAG 는 집약체…NLP의 모든 시도를 다 해봐야 함. 이후 반복적인 테스트 케이스 추가를 다시 해야함. 테스트 케이스 만들 때 ChatGPT로 Synthtic Data 를 만들어시멘틱 서치시 검색할 문서가 너무 많음…그래서  천킹(단어길이가 이닌 시멘틱하게 커팅하는 방식)을 시도해야 함.**

 

positive pair 10개 질문 negative pair 질문 10개. 각 컨텐츠와 cosine embedding loss를 수치로 계산

1. 기존 질문과 비슷한 general한 질문.
- 에너지 균형을 유지하기 위해 식단과 운동에서 주의할 점은 무엇인가요?
- 수소 분자가 다른 분자보다 빠르게 움직이는 이유는 무엇인가요?
- 종이와 플라스틱의 재활용 방식이 다른 이유는 무엇인가요?
- 에너지 소비와 섭취의 균형이 건강에 중요한 이유는 무엇인가요?
- 수소가 화학 반응에서 활발하게 참여하는 이유는 무엇인가요?
- 플라스틱이 자연 분해되기 어려운 이유는 무엇인가요?
- 건강한 사람의 에너지 균형을 유지하기 위해 권장되는 기간은 얼마인가요?
- 운동이 에너지 소비를 촉진하는 원리는 무엇인가요?
- 종이가 자연적으로 분해되는데 플라스틱은 그렇지 못한 이유는 무엇인가요?
- 재생 가능한 자원이 환경에 미치는 긍정적인 영향은 무엇인가요?

### Positive Pair (CosineEmbeddingLoss = 1)

1. 원자핵이 무엇인가요? / 원자의 중심에 위치한 원자핵이란 무엇인가요?
2. 지구의 자전이란 무엇인가요? / 지구가 자전하는 과정은 무엇인가요?
3. 세포가 하는 역할은 무엇인가요? / 세포가 생물체에서 어떤 기능을 하는지 설명해주세요.
4. 중력의 정의는 무엇인가요? / 중력은 어떤 힘인가요?
5. 물질의 상태 변화는 무엇인가요? / 고체, 액체, 기체로 물질이 변화하는 것을 상태 변화라고 하나요?
6. 태양 에너지는 어떻게 사용되나요? / 태양 에너지를 활용하는 방법은 무엇인가요?
7. 식물이 광합성을 하는 이유는 무엇인가요? / 식물이 광합성을 통해 에너지를 얻는 이유는 무엇인가요?
8. 열 에너지는 어떻게 발생하나요? / 열 에너지가 발생하는 원리는 무엇인가요?
9. 바이러스는 어떻게 전염되나요? / 바이러스가 다른 개체로 전염되는 방식은 무엇인가요?
10. 달은 왜 지구 주위를 도나요? / 달이 지구 궤도를 도는 이유는 무엇인가요?

### Negative Pair (CosineEmbeddingLoss = -1)

1. 원자핵이 무엇인가요? / 바다의 염도는 왜 중요한가요?
2. 지구의 자전이란 무엇인가요? / 유전자는 생물체에 어떤 영향을 주나요?
3. 세포가 하는 역할은 무엇인가요? / 블랙홀은 어떻게 형성되나요?
4. 중력의 정의는 무엇인가요? / 산소는 호흡 과정에서 어떤 역할을 하나요?
5. 물질의 상태 변화는 무엇인가요? / 광합성은 어떻게 이루어지나요?
6. 태양 에너지는 어떻게 사용되나요? / 전자기파는 어떻게 발생하나요?
7. 식물이 광합성을 하는 이유는 무엇인가요? / 유전자가 어떻게 전달되나요?
8. 열 에너지는 어떻게 발생하나요? / 원자는 어떤 구조로 이루어져 있나요?
9. 바이러스는 어떻게 전염되나요? / 에너지는 어떻게 보존되나요?
10. 달은 왜 지구 주위를 도나요? / 태풍은 어떻게 발생하나요?

- 작업을 진행하면서 결과물에대해 팀원들끼리 합의가 안됬을시(인간끼리 합의가 안됬을때)→ 결국 테스트케이스가 부족해서 이다. 테스트케이스로 증명해야된다.

참고자료. 

- https://arxiv.org/search/   (논문을 간결하게 보기위해 metric을 찾을것)
- https://www.elastic.co/search-labs/blog/evaluating-rag-metrics
- https://cookbook.openai.com/

참조 인용: [https://github.com/su-park/mteb_ko_leaderboard?tab=readme-ov-file#mteb-평가](https://github.com/su-park/mteb_ko_leaderboard?tab=readme-ov-file#mteb-%ED%8F%89%EA%B0%80)

**MTEB 평가**

---

- 텍스트 임베딩의 성능을 다면적으로 평가하기 위한 벤치마크 셋
- 평가셋이 대부분 영어 위주로 구성되어 아래에서는 한글 데이터셋만 대상으로 성능 측정

| Task | Definition | Metric |
| --- | --- | --- |
| BitextMining | task of finding parallel sentences in two languages | F1 |
| Classification | task of assigning a label to a text | Accuracy |
| Clustering | task of grouping similar documents together | Validity Measure (V-measure) |
| PairClassification | task of determining whether two texts are similar | Average Precision |
| Reranking | task of reordering a list of documents to improve relevance | Mean Average Precision |
| Retrieval | task of finding relevant documents for a query | nDCG@10 |
| STS | task of determining how similar two texts are | Spearman Correlation |

**성능 평가**

---

| no. | Model | BitextMining kor-eng | BitextMining eng-kor | Classification | MultiLabel Classification | Clustering | PairClassification | Reranking | Retrieval | STS |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | `SFR-Embedding-2_R` | 94.49 | 95.79 | 68.74 | 9.80 | 53.78 | 60.42 | 48.17 | 73.18 | 81.16 |
| 2 | `gte-Qwen2-7B-instruct` | 94.32 | 95.11 | **72.33** | 9.22 | 53.27 | **74.15** | 50.05 | 74.96 | **85.70** |
| 3 | `bge-multilingual-gemma2` | 94.78 | 95.56 | 69.06 | **13.14** | 40.10 | 68.98 | 37.06 | 58.87 | 83.83 |
| 4 | `e5-mistral-7b-instruct` | 94.53 | **95.94** | 67.47 | 9.08 | **58.02** | 63.08 | 54.92 | 63.08 | 84.54 |
| 5 | `jina-embeddings-v3` | 91.70 | 91.95 | 63.17 | 12.03 | 39.83 | 56.93 | 42.95 | **74.98** | 83.50 |
| 6 | `LLM2Vec-Meta-Llama-3-supervised` | 94.37 | 95.33 | 68.27 | 9.37 | 47.01 | 65.45 | 52.63 | 68.43 | 83.44 |
| 7 | `multilingual-e5-large-instruct` | **94.91** | 95.83 | 67.03 | 10.20 | 55.76 | 61.18 | 52.86 | 74.52 | 85.15 |
| 8 | `multilingual-e5-large` | 93.64 | 94.33 | 62.96 | 9.18 | 39.02 | 57.55 | 54.87 | 73.47 | 80.62 |
| 9 | `bge-m3` | 94.53 | 95.81 | 63.48 | 10.92 | 38.04 | 61.20 | **59.98** | 72.29 | 83.13 |
| 10 | `ko-sroberta-multitask` | 69.66 | 57.56 | 61.62 | 8.93 | 36.41 | 65.64 | 48.33 | 60.98 | 85.39 |
|  | `bge-m3-korean` | 93.32 | 94.82 | 58.89 | 9.21 | 23.967 | 64.13 | 52.44 | 67.94 | 85.43 |
|  | `KoE5` | 93.00 | 93.92 | 64.56 | 11.57 | 43.24 | 57.37 | 54.14 | 73.69 | 82.15 |

| no. | Model | Tatoeba BitextMining kor-eng | Flores BitextMining eng-kor | Flores BitextMining kor-eng | NTREX BitextMining eng-kor | NTREX BitextMining kor-eng | IWSLT2017 BitextMining eng-kor | IWSLT2017 BitextMining kor-eng | MassiveIntent Classification | MassiveScenario Classification | Klue-TC Classification | SIB200 Classification | MultilingualSentiment Classification | KorHate Classification | KorSarcasm Classification | KorHateSpeechML MultiLabel Classification | SIB200ClusteringS2S Clustering | Klue-NLI PairClassification | PawsX PairClassification | MIRACL Reranking | Ko-StrategyQA Retrieval | XPQA Retrieval | PublicHealthQA Retrieval | Belebele Retrieval | MIRACL Retrieval | STS17 STS | KorSTS STS | Klue-STS STS |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | `SFR-Embedding-2_R` | 91.04 | 100.00 | 100.00 | 98.81 | 99.33 | 88.57 | 87.59 | 75.40 | 85.67 | 58.50 | 80.19 | 79.68 | 45.57 | 56.15 | 9.80 | 53.78 | 67.49 | 53.34 | 48.17 | 77.27 | 37.24 | 86.35 | 91.85 | 47.01 | 78.86 | 77.39 | 87.24 |
| 2 | `gte-Qwen2-7B-instruct` | 91.40 | **100.00** | **100.00** | 98.83 | 99.09 | 86.51 | 86.77 | **79.25** | **86.42** | **69.20** | **86.12** | 78.22 | 46.94 | **60.13** | 9.22 | 53.27 | 79.57 | **68.72** | 50.05 | **81.07** | 37.81 | 86.15 | **94.79** |  | 83.86 | 83.47 | **89.77** |
| 3 | `bge-multilingual-gemma2` | **92.35** | 100.00 | 99.86 | 98.16 | 98.99 | 88.51 | 87.90 | 73.56 | 81.10 | 63.61 | 77.15 | **81.69** | **48.84** | 57.46 | **13.14** | 40.10 | **80.12** | 57.84 | 37.06 | 51.33 | 37.67 | 65.89 | 80.59 | 19.57 | 81.38 | 81.61 | 88.49 |
| 4 | `e5-mistral-7b-instruct` | 91.28 | 100.00 | 100.00 | 98.68 | 99.13 | 89.15 | 87.71 | 69.87 | 74.39 | 60.15 | 84.16 | 80.74 | 45.97 | 57.01 | 9.08 | **58.02** | 73.02 | 53.14 | 54.92 | 79.30 | 39.22 | **88.71** | 92.61 |  | 83.69 | 82.27 | 87.65 |
| 5 | `jina-embeddings-v3` | 86.93 | 97.89 | 99.07 | 93.05 | 95.63 | 84.92 | 85.16 | 62.32 | 70.16 | 58.72 | 74.75 | 74.12 | 42.23 | 59.87 | 12.03 | 39.83 | 62.11 | 51.74 | 42.95 | 78.35 | **41.67** | 87.92 | 91.98 |  | 84.00 | 82.53 | 83.98 |
| 6 | `LLM2Vec-Meta-Llama-3-supervised` | 90.94 | 100.00 | 99.86 | 98.07 | 98.82 | 87.92 | 87.86 | 75.15 | 79.87 | 60.83 | 79.85 | 79.30 | 44.58 | 58.33 | 9.37 | 47.01 | 77.57 | 53.33 | 52.63 | 70.44 | 36.58 | 79.76 | 86.95 | 34.90 | 81.22 | 81.06 | 88.03 |
| 7 | `multilingual-e5-large-instruct` | 91.76 | 100.00 | 100.00 | **99.08** | **99.39** | 88.42 | 88.49 | 64.15 | 70.50 | 62.24 | 81.71 | 78.29 | 45.30 | 58..17 | 10.20 | 55.76 | 70.54 | 51.81 | 52.86 | 79.86 | 39.74 | 84.87 | 93.60 |  | 84.30 | 82.71 | 88.44 |
| 8 | `multilingual-e5-large` | 89.70 | 99.42 | 99.86 | 96.46 | 98.93 | 87.11 | 86.08 | 63.74 | 70.66 | 59.68 | 74.60 | 72.57 | 43.18 | 56.26 | 9.18 | 39.02 | 63.42 | 51.68 | 54.87 | 79.82 | 36.99 | 82.88 | 94.18 | 65.56 | 81.04 | 79.24 | 81.59 |
| 9 | `bge-m3` | 90.44 | 99.86 | 100.00 | 98.60 | 99.08 | **88.96** | **88.59** | 66.53 | 72.90 | 54.67 | 71.91 | 78.16 | 43.38 | 56.79 | 10.92 | 38.04 | 70.05 | 52.34 | **59.98** | 79.40 | 36.15 | 80.41 | 93.18 | **70.14** | 81.42 | 80.26 | 87.70 |
| 10 | `ko-sroberta-multitask` | 61.05 | 72.31 | 86.39 | 52.16 | 71.95 | 48.20 | 59.26 | 64.80 | 70.12 | 52.10 | 69.75 | 73.82 | 43.67 | 57.11 | 8.93 | 36.41 | 78.38 | 52.89 | 48.33 | 65.10 | 27.96 | 69.21 | 81.63 | 36.69 | **86.46** | **85.58** | 84.13 |
|  | `bge-m3-korean` | 89.36 | 99.73 | 100.00 | 98.21 | 98.20 | 86.54 | 85.75 | 66.28 | 72.80 | 41.23 | 59.95 | 74.98 | 41.34 | 55.69 | 9.21 | 23.97 | 75.95 | 52.32 | 52.44 | 75.27 | 31.66 | 77.55 | 87.31 |  | 85.15 | 83.34 | 87.81 |
|  | `KoE5` | 89.41 | 99.47 | 99.73 | 96.78 | 97.39 | 85.51 | 85.47 | 66.35 | 74.13 | 63.74 | 74.85 | 73.05 | 43.92 | 55.90 | 11.57 | 43.24 | 61.71 | 53.03 | 54.14 | 79.76 | 36.13 | 84.49 | 94.41 |  | 81.35 | 79.45 | 85.65 |

---

-정보찾는법

-metric for search

-anxiv   → Rag survey 

서베이를 참조 rag tutorial survey

논문을 찾으면 metric을 찾아볼 것. 

search metric survey.
